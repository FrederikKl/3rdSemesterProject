{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import logging\n",
    "import gc\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
    "from azure.core.exceptions import ResourceExistsError\n",
    "import tracemalloc\n",
    "import sys\n",
    "from concurrent_log_handler import ConcurrentRotatingFileHandler  # Updated log handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Azure configuration\n",
    "AZURE_ACCOUNT_NAME = os.getenv('AZURE_STORAGE_ACCOUNT_NAME')\n",
    "AZURE_ACCOUNT_KEY = os.getenv('AZURE_STORAGE_ACCOUNT_KEY')\n",
    "AZURE_CONTAINER_NAME = os.getenv('AZURE_CONTAINER_NAME')\n",
    "LOCAL_FOLDER = os.getenv('LOCAL_FOLDER_PATH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blob service client\n",
    "blob_service_client = BlobServiceClient(\n",
    "    account_url=f\"https://{AZURE_ACCOUNT_NAME}.blob.core.windows.net\",\n",
    "    credential=AZURE_ACCOUNT_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or get container\n",
    "container_client = blob_service_client.get_container_client(AZURE_CONTAINER_NAME)\n",
    "try:\n",
    "    container_client.create_container()\n",
    "except ResourceExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start memory tracking\n",
    "tracemalloc.start()\n",
    "\n",
    "# Initialize logger with file handler\n",
    "log_file = \"upload_sync.log\"\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.WARNING)  # Set logging to WARNING to reduce verbosity\n",
    "\n",
    "# Add file handler for logging\n",
    "handler = logging.FileHandler(log_file)\n",
    "formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get last modified time of file\n",
    "def get_file_last_modified(file_path):\n",
    "    return datetime.fromtimestamp(os.path.getmtime(file_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload file in chunks to blob\n",
    "def upload_blob_in_chunks(blob_client, file_path):\n",
    "    with open(file_path, \"rb\") as data:\n",
    "        blob_client.upload_blob(data, overwrite=True, max_concurrency=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process a batch of files\n",
    "def process_batch(batch, blobs_metadata):\n",
    "    newly_added_count = 0\n",
    "    overwritten_count = 0\n",
    "\n",
    "    for file_path, blob_name in batch:\n",
    "        try:\n",
    "            if blob_name in blobs_metadata:\n",
    "                blob_last_modified = blobs_metadata[blob_name].timestamp()\n",
    "                local_last_modified = get_file_last_modified(file_path).timestamp()\n",
    "\n",
    "                if local_last_modified > blob_last_modified:\n",
    "                    upload_blob_in_chunks(container_client.get_blob_client(blob_name), file_path)\n",
    "                    overwritten_count += 1\n",
    "            else:\n",
    "                upload_blob_in_chunks(container_client.get_blob_client(blob_name), file_path)\n",
    "                newly_added_count += 1\n",
    "\n",
    "            # Clear file from memory\n",
    "            file_path = None\n",
    "            blob_name = None\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "    return newly_added_count, overwritten_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator to yield files in the local folder\n",
    "def file_generator(root_folder):\n",
    "    for root, dirs, files in os.walk(root_folder):\n",
    "        for filename in files:\n",
    "            file_path = os.path.join(root, filename)\n",
    "            blob_name = os.path.relpath(file_path, root_folder).replace(\"\\\\\", \"/\")\n",
    "            yield file_path, blob_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sync local files to Azure Blob and report\n",
    "def sync_local_to_blob_and_report(batch_size_in_bytes=1024 * 1024, max_documents=1000):\n",
    "    logger.info(\"Starting sync with Azure Blob Storage...\")\n",
    "\n",
    "    # 1. Fetch the initial blob metadata and count\n",
    "    blobs_metadata = {blob.name: blob.last_modified for blob in container_client.list_blobs()}\n",
    "    total_blobs_in_container = len(blobs_metadata)  # Initial blob count\n",
    "    logger.warning(f\"Total blobs found in container: {total_blobs_in_container}\")\n",
    "\n",
    "    # 2. Get the total number of local files\n",
    "    total_local_files = sum(1 for _ in file_generator(LOCAL_FOLDER))\n",
    "    logger.warning(f\"Total local files to sync: {total_local_files}\")\n",
    "\n",
    "    total_newly_added_count = 0\n",
    "    total_overwritten_count = 0\n",
    "    current_batch = []\n",
    "    current_batch_size = 0\n",
    "    total_uploaded = 0\n",
    "\n",
    "    # Process files in batches\n",
    "    for file_path, blob_name in file_generator(LOCAL_FOLDER):\n",
    "        file_size = os.path.getsize(file_path)\n",
    "        current_batch.append((file_path, blob_name))\n",
    "        current_batch_size += file_size\n",
    "\n",
    "        # Process batch when size exceeds limit\n",
    "        if current_batch_size >= batch_size_in_bytes:\n",
    "            newly_added, overwritten = process_batch(current_batch, blobs_metadata)\n",
    "            total_newly_added_count += newly_added\n",
    "            total_overwritten_count += overwritten\n",
    "            total_uploaded += len(current_batch)\n",
    "\n",
    "            # Reset batch\n",
    "            current_batch.clear()\n",
    "            current_batch_size = 0\n",
    "\n",
    "            # Free memory after each batch\n",
    "            gc.collect()\n",
    "\n",
    "        # Restart if max documents reached\n",
    "        if total_uploaded >= max_documents:\n",
    "            total_uploaded = 0\n",
    "            blobs_metadata = {blob.name: blob.last_modified for blob in container_client.list_blobs()}\n",
    "            gc.collect()\n",
    "\n",
    "    # Process remaining files in the final batch\n",
    "    if current_batch:\n",
    "        newly_added, overwritten = process_batch(current_batch, blobs_metadata)\n",
    "        total_newly_added_count += newly_added\n",
    "        total_overwritten_count += overwritten\n",
    "        current_batch.clear()\n",
    "        gc.collect()\n",
    "\n",
    "    # 3. Fetch the final blob count in the container\n",
    "    final_blob_count = len(list(container_client.list_blobs()))  # Final blob count\n",
    "\n",
    "    # 4. Log the summary\n",
    "    logger.warning(\"----- Sync Summary -----\")\n",
    "    logger.warning(f\"Initial number of blobs: {total_blobs_in_container}\")\n",
    "    logger.warning(f\"Total local files: {total_local_files}\")\n",
    "    logger.warning(f\"Total newly added files: {total_newly_added_count}\")\n",
    "    logger.warning(f\"Total overwritten files: {total_overwritten_count}\")\n",
    "    logger.warning(f\"Final number of blobs in storage: {final_blob_count}\")\n",
    "    logger.warning(\"------------------------\")\n",
    "\n",
    "    logger.info(\"Sync process complete.\")\n",
    "    return\n",
    "\n",
    "# Run the sync process\n",
    "if __name__ == \"__main__\":\n",
    "    sync_local_to_blob_and_report(batch_size_in_bytes=1024 * 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
