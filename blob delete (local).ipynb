{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import logging\n",
    "import gc\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient\n",
    "from azure.core.exceptions import ResourceExistsError\n",
    "import tracemalloc\n",
    "import sys\n",
    "from concurrent_log_handler import ConcurrentRotatingFileHandler  # Updated log handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Azure configuration\n",
    "AZURE_ACCOUNT_NAME = os.getenv('AZURE_STORAGE_ACCOUNT_NAME')\n",
    "AZURE_ACCOUNT_KEY = os.getenv('AZURE_STORAGE_ACCOUNT_KEY')\n",
    "AZURE_CONTAINER_NAME = os.getenv('AZURE_CONTAINER_NAME')\n",
    "LOCAL_FOLDER = os.getenv('LOCAL_FOLDER_PATH')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blob service client\n",
    "blob_service_client = BlobServiceClient(\n",
    "    account_url=f\"https://{AZURE_ACCOUNT_NAME}.blob.core.windows.net\",\n",
    "    credential=AZURE_ACCOUNT_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or get container\n",
    "container_client = blob_service_client.get_container_client(AZURE_CONTAINER_NAME)\n",
    "try:\n",
    "    container_client.create_container()\n",
    "except ResourceExistsError:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize logger with file handler\n",
    "log_file = \"upload_sync.log\"\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.WARNING)  # Set logging to WARNING to reduce verbosity\n",
    "\n",
    "# Ensure the logger is only added once\n",
    "if not logger.handlers:  # Check if handlers are already set\n",
    "    handler = logging.FileHandler(log_file)\n",
    "    formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_local_files_with_relative_paths(local_folder):\n",
    "    \"\"\" Recursively list all files in a local folder with their relative paths \"\"\"\n",
    "    local_files = set()\n",
    "    for root, _, files in os.walk(local_folder):\n",
    "        for file in files:\n",
    "            # Get the relative path of the file, relative to the base local folder\n",
    "            relative_path = os.path.relpath(os.path.join(root, file), local_folder)\n",
    "            # Normalize for cross-platform compatibility (Unix and Windows)\n",
    "            relative_path = relative_path.replace(\"\\\\\", \"/\")\n",
    "            local_files.add(relative_path)\n",
    "    return local_files\n",
    "\n",
    "local_files = list_local_files_with_relative_paths(LOCAL_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sync_blob_storage_with_local(batch_size_in_bytes=1024 * 1024):\n",
    "    # Initialize counters and accumulators\n",
    "    blobs_to_delete = []\n",
    "    total_deleted_count = 0\n",
    "    current_batch_size = 0\n",
    "    \n",
    "    # List all blobs in the container\n",
    "    blob_list = container_client.list_blobs()  # This returns an iterable object for all blobs in Azure\n",
    "    \n",
    "    \n",
    "    # Iterate through blobs in Azure\n",
    "    for blob in blob_list:\n",
    "        blob_name = blob.name  # Keep the full blob name (which includes subfolders in Azure)\n",
    "        blob_size = blob.size  # Get the blob size in bytes\n",
    "\n",
    "        # Check if the blob name exists in the local file set\n",
    "        if blob_name not in local_files:\n",
    "            # Blob does not exist locally, mark it for deletion\n",
    "            blobs_to_delete.append(blob_name)\n",
    "            total_deleted_count += 1\n",
    "        \n",
    "        # Add the blob's size to the current batch and check if batch size limit is reached\n",
    "        current_batch_size += blob_size\n",
    "        if current_batch_size >= batch_size_in_bytes:\n",
    "            current_batch_size = 0  # Reset batch size accumulator\n",
    "            gc.collect()\n",
    "    \n",
    "    # Deleting blobs that don't exist in the local folder anymore\n",
    "    if blobs_to_delete:\n",
    "        for blob_name in blobs_to_delete:\n",
    "            try:\n",
    "                container_client.delete_blob(blob_name)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error deleting blob {blob_name}: {e}\")\n",
    "\n",
    "    # Log the summary only once after the deletion process\n",
    "    logger.warning(f\"Total deleted files: {total_deleted_count}\")\n",
    "    final_blob_count = len(list(container_client.list_blobs()))  # Final count of blobs\n",
    "    logger.warning(f\"Final number of blobs in storage: {final_blob_count}\")\n",
    "\n",
    "# Run the sync process\n",
    "if __name__ == \"__main__\":\n",
    "    sync_blob_storage_with_local(batch_size_in_bytes=1024 * 1024)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
